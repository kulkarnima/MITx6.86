{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b0b586c",
   "metadata": {
    "id": "9b0b586c"
   },
   "source": [
    "## Digit recognition Demo\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "__YJBLW9vd5c",
   "metadata": {
    "id": "__YJBLW9vd5c"
   },
   "source": [
    "### Intro\n",
    "Recognizing a handwritten digit is intuitive for the human eye, as we can effortlessly discern beween a scribbeled '7' and a rushed '2'. Yet, for machines, this is an intricate challenge. Imagine trying to teach a toddler to identify numbers, but with matrices of pixels, algorithms and various model architectures.In this demo, our journey begins with straightforward linear models. As we progress, we explore feed-forward neural networks, which use interconnected web of nodes to resemble how our brains process new information. Then, we navigate through convolutional neural networks (CNNs), designed to mimic the human visual system. With these tools in mind, we hope you can have a deeper understanding of neural networks and appreciate the power of machine learningalgorithms.\n",
    "\n",
    " For this demo, we will be using the MNIST dataset, which contains a vastcollection of handwritten digits that have been used in the machine learning community for years. Each image in this dataset is 28 × 28 pixels in size and represents a grayscale image of a single digit. So why should we care about classifying these images? Imagine a post office sorting through zip codes or a bank reading handwritten checks- having a machine to automatically recognize the digits with high accuracy can be very useful. The dataset contains 60,000 training samples and 10,00 testing samples, with a similar number of samples for each digit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LylAsVwrvWqI",
   "metadata": {
    "id": "LylAsVwrvWqI"
   },
   "source": [
    "### Load data and Pre-Process\n",
    "We first load the required packages and the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bf2dad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c6bf2dad",
    "outputId": "5727b680-e392-432a-97d0-553a026dc26b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeec0c78",
   "metadata": {
    "id": "eeec0c78"
   },
   "source": [
    " Here, we load the MNIST dataset, which is split between training and testing split. More specifically, x_train is a (60000 x 28 x 28) numpy array of integers[0, 255], and y_train is a (60000, ) numpy array of labels [0, 10). To simplify our task, we consider binary classification where we zoom into two digits: 4 and 9. This choice allows us to understand the fundamental concepts of classification before tackling all ten digits. Let’s define some global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcb5b8d",
   "metadata": {
    "id": "6fcb5b8d"
   },
   "outputs": [],
   "source": [
    "DIG_A, DIG_B = 4, 9\n",
    "SIDE = 28\n",
    "MAX_PIX_VAL = 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ab5078",
   "metadata": {
    "id": "f1ab5078"
   },
   "source": [
    "and keep only the images of digits 4 and 9. To make our computations more stable and faster, we normalize our image data to have values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cde75a3",
   "metadata": {
    "id": "3cde75a3"
   },
   "outputs": [],
   "source": [
    "indices = np.logical_or((y_train == DIG_A), (y_train == DIG_B))\n",
    "x_train = x_train[indices]\n",
    "y_train = y_train[indices]\n",
    "x_train = x_train/MAX_PIX_VAL\n",
    "N = len(x_train)\n",
    "\n",
    "assert(len(x_train) == len(y_train))\n",
    "'''\n",
    "assert(x_train.shape == (N,))\n",
    "'''\n",
    "assert(set(y_train) == {DIG_A, DIG_B})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf29023",
   "metadata": {
    "id": "7bf29023"
   },
   "source": [
    "It is crucial to randomize our dataset to ensure that the model does not accidentally learn any pattern from the order in which samples are presented. We also fix the seed to ensure code reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11cea1d",
   "metadata": {
    "id": "d11cea1d"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "indices = np.arange(len(x_train))\n",
    "np.random.shuffle(indices)\n",
    "x_train = x_train[indices]\n",
    "y_train = y_train[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de6f2f0",
   "metadata": {
    "id": "3de6f2f0"
   },
   "source": [
    "Let us define the function close_enough to check if the data is appropriately normalized. Furthermore, given that there are roughly equal numbers of each digit in the dataset, we should have close to 12,000 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5b6410",
   "metadata": {
    "id": "7a5b6410"
   },
   "outputs": [],
   "source": [
    "close_enough = lambda a, b: abs(b-a) <= 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a4c981",
   "metadata": {
    "id": "77a4c981"
   },
   "outputs": [],
   "source": [
    "assert(close_enough(np.min(x_train), 0.))\n",
    "assert(close_enough(np.max(x_train), 1.))\n",
    "assert(abs(N - 12000) < 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c44e59f",
   "metadata": {
    "id": "6c44e59f"
   },
   "source": [
    "### Evaluate Predictors\n",
    "Next, we define some functions to evaluate how good our model is using accuracy and cross-entropy loss. The judge function is a handy tool that lets us get both metrics for any predictors we pass in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16819991",
   "metadata": {
    "id": "16819991"
   },
   "outputs": [],
   "source": [
    "def accuracy(predicted_labels, true_ys):\n",
    "    return np.mean([1. if l==y else 0. for l, y in zip(predicted_labels, true_ys)])\n",
    "\n",
    "def cross_entropy_loss(predicted_probs, true_ys):\n",
    "    return np.mean([-np.log(p if y==DIG_B else 1.-p) for p, y in zip(predicted_probs, true_ys)])\n",
    "\n",
    "def judge(predictor, xs, ys):\n",
    "    probs = [predictor(x) for x in xs]\n",
    "    labels = [DIG_B if p > 0.5 else DIG_A for p in probs]\n",
    "    acc = accuracy(labels, ys)\n",
    "    loss = cross_entropy_loss(probs, ys)\n",
    "    return {'acc': acc, 'loss': loss}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433efec0",
   "metadata": {
    "id": "433efec0"
   },
   "source": [
    "### Dummy Predictors\n",
    "Before diving in to complicated predictiv emodels, let us define some dummy predictor functions that completely ignore the input image. They can either be very certain or uncertain about their prediction, or a fifty-fifty coin toss. These models, while naive in their predictions, give us a perspective on what’s achievable if we took a very basic approach to predicting our digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c833965c",
   "metadata": {
    "id": "c833965c"
   },
   "outputs": [],
   "source": [
    "very_sure_A = lambda x: 0.01\n",
    "very_sure_B = lambda x: 0.99\n",
    "maybe_its_A = lambda x: 0.4\n",
    "maybe_its_B = lambda x: 0.6\n",
    "fifty_fifty = lambda x: 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31113e6e",
   "metadata": {
    "id": "31113e6e"
   },
   "source": [
    "`very_sure_A` and `very_sure_B` arepredictors that are, as their name ssuggest,very sure about their predictions.The former always thinks the digitis ’A’ (or in our case, ’4’), while the latter is adamant it’s ’B’ (or’9’). These models don’t even look at the input image; they just confidently guess one digit. We can assert that the combined accuracy of the two models must sum up to one,because if one is correct, the other has to be incorrect, or vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a628df9",
   "metadata": {
    "id": "5a628df9"
   },
   "outputs": [],
   "source": [
    "vsa = judge(very_sure_A, x_train, y_train)['acc']\n",
    "vsb = judge(very_sure_B, x_train, y_train)['acc']\n",
    "assert(close_enough(vsa + vsb, 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac80876",
   "metadata": {
    "id": "cac80876"
   },
   "outputs": [],
   "source": [
    "vsa = judge(very_sure_A, x_train[:1], [DIG_A])['acc']\n",
    "vsb = judge(very_sure_A, x_train[:1], [DIG_B])['acc']\n",
    "assert(close_enough(vsa, 1.))\n",
    "assert(close_enough(vsb, 0.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88871d17",
   "metadata": {
    "id": "88871d17"
   },
   "source": [
    "Lastly,we examine the loss of these predictors, which gives us a measure of how off the predictors are from the truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d87cde0",
   "metadata": {
    "id": "7d87cde0"
   },
   "outputs": [],
   "source": [
    "vsa = judge(very_sure_A, x_train, y_train)['loss']\n",
    "vsb = judge(very_sure_B, x_train, y_train)['loss']\n",
    "mia = judge(maybe_its_A, x_train, y_train)['loss']\n",
    "mib = judge(maybe_its_B, x_train, y_train)['loss']\n",
    "ffl = judge(fifty_fifty, x_train, y_train)['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c097f921",
   "metadata": {
    "id": "c097f921"
   },
   "source": [
    "Cross-entropy loss quantifies the difference between two probability distributions, typically the true distribution and our model’s predictions. For the binary classification task, cross-entropy loss heavily penalizes a confident but incorrect prediction. Recall the formula for cross-entropy loss for binary classification:\n",
    "$$\n",
    " L =−y·log(p)−(1−y)·log(1−p)\n",
    " $$\n",
    "\n",
    "where $y$ is the true label, and p is the predicted probability of the label being 1. Therefore, for `very_sure_A`, the predictor encounters a near-zero loss for correct predictions, but a heavy penalty when making a confident but incorrect prediction. On the other hand, `maybe_its_A` makes predictions with lower confidence, thus encounters a more moderate loss for both correct and incorrect predictions.\n",
    "\n",
    " `fifty_fifty` always suggests that either digit is equally probable, thus the cross-entropy loss is simply $−log(1/2) = log2$. Given that the dataset contains similar number of samples for each label, `fifty_fifty` yields predictions that are closest to the baseline distribution. As the predictors become more extreme, each incorrect prediction yields heavier penalty that outweights a lower loss of correction prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd19eae1",
   "metadata": {
    "id": "fd19eae1"
   },
   "outputs": [],
   "source": [
    "assert(ffl < mia < vsa)\n",
    "assert(ffl < mib < vsb)\n",
    "assert(close_enough(ffl, np.log(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011d422c",
   "metadata": {
    "id": "011d422c"
   },
   "source": [
    "**Q:** what if the distribution of the two samples is skewed? For example, how will the cross-entropy loss relationship change if 90% of the samples are ’A’?\n",
    "\n",
    "### Linear Models\n",
    "The journey of creating a linear model often starts with the activation function.In this case, we’re using the sigmoid function:\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{(1+e^{-z}))}\n",
    "$$\n",
    "\n",
    "In order to ensure numerical stability, we clip the value of $z$ between −15 and 15 as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8beee04",
   "metadata": {
    "id": "d8beee04"
   },
   "outputs": [],
   "source": [
    "clip = lambda z: np.clip(z, -15, 15)\n",
    "sigmoid = lambda z: 1./(1.+np.exp(-clip(z)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9a3d64",
   "metadata": {
    "id": "9c9a3d64"
   },
   "source": [
    "With our activation function defined, let’s build our predictor! The linear prediction is simply the weighted sum of the input data passed through the sigmoid function. Here, we flatten the input into a 1D array, given that it is a 28 × 28 array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dee7163",
   "metadata": {
    "id": "9dee7163"
   },
   "outputs": [],
   "source": [
    "def linear_predict(w, x):\n",
    "    return sigmoid(w.dot(x.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3fa59b",
   "metadata": {
    "id": "6f3fa59b"
   },
   "source": [
    "We initialize the w with random weights, similar to how a neural network is initialized. This is the linear mapping from the input. Here, we initialize $w$ with values drawn from a normal distribution normalized by diving the square root of the total number of pixels. This is to prevent any random weight from starting too large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed8b350",
   "metadata": {
    "id": "0ed8b350"
   },
   "outputs": [],
   "source": [
    "w = np.random.randn(SIDE*SIDE) / np.sqrt(SIDE*SIDE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d7ff79",
   "metadata": {
    "id": "16d7ff79"
   },
   "source": [
    "Let’s perform a sanity check on our linear implementation so far. Consider the predictor with our random weights $w$, we obtain a prediction based on the weighted sum of the values in $x$. If we feed the same sample, the weighted sum becomes the exact negative of the previous weighted sum because the weights are the negatives of the original weights. This will essentially mirror the input value of the sigmoid function from one side to the other. Since the sigmoid function is symmetric around the vertical line $z = 0$ (where $\\sigma(z) = 0.5$), if we get a value greater than 0.5 using $w$, we must get a value less than 0.5 using the negative weights $-w$, and vice versa. In other words, flipping the sign of $w$ guarantees that the two predictors will always make opposite predictions for any sample, and their respective confidence scores (the raw outputs of the sigmoid) will sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816acb9b",
   "metadata": {
    "id": "816acb9b"
   },
   "outputs": [],
   "source": [
    "vsa = judge(lambda x: linear_predict(+w, x), x_train, y_train)['acc']\n",
    "vsb = judge(lambda x: linear_predict(-w, x), x_train, y_train)['acc']\n",
    "assert(close_enough(vsa+vsb, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e57dce1",
   "metadata": {
    "id": "6e57dce1"
   },
   "source": [
    "We can also consider a special case of zero weights. In this case, all predictions have a 50-50 chance, and the associated loss must be approximately $log(2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f844d17e",
   "metadata": {
    "id": "f844d17e"
   },
   "outputs": [],
   "source": [
    "ffl = judge(lambda x: linear_predict(0*w, x), x_train, y_train)['loss']\n",
    "assert(close_enough(ffl, np.log(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9514061",
   "metadata": {
    "id": "e9514061"
   },
   "source": [
    "Let’s do another interesting experiment. Suppose we create a random image $x$ using the random weights. In this case, the dot product between $w$ and $x$ will always be positive, thus the prediction will always be in favor of digit B. To verify this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca28123",
   "metadata": {
    "id": "bca28123"
   },
   "outputs": [],
   "source": [
    "x = w.reshape(SIDE, SIDE)\n",
    "vsa = judge(lambda x: linear_predict(w, x), [x], [DIG_A])['acc']\n",
    "vsb = judge(lambda x: linear_predict(w, x), [x], [DIG_B])['acc']\n",
    "assert(close_enough(vsa, 0.))\n",
    "assert(close_enough(vsb, 1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ca9705",
   "metadata": {
    "id": "f6ca9705"
   },
   "source": [
    "#### Linear Backpropagation\n",
    "The term \"backpropagation\" is typically used for neural networks, but we can apply the same concept to linear models. In essence, it is the math behind adjusting the weights and learning from errors to get a better model. Consider the loss function\n",
    "$$\n",
    "L = CEL(\\sigma(w.x))\n",
    "$$\n",
    "\n",
    "where _CEL_ denots the cross-entropy loss and $\\sigma$ denotes the sigmoid function. Here, we use the chain rule to obtain the gradient of the loss function with respect to the weights. Let $z \\triangleq w.x$, and $p \\triangleq \\sigma(x)$, we have:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w} = \\frac{\\partial L}{\\partial p}.\\frac{\\partial p}{\\partial z}.\\frac{\\partial z}{\\partial w}\n",
    "$$\n",
    "\n",
    "Recall the cross-entropy loss for binary classications, we have:\n",
    "\n",
    "$$\n",
    "L(p, y) = \\begin{cases}\n",
    "            -log(p)   \\qquad\\qquad if\\quad y = \\mathrm{DIG\\_B} \\\\\n",
    "            -log(1-p) \\qquad  \\mathrm{otherwise}\n",
    "          \\end{cases}\n",
    "$$\n",
    "\n",
    "Taking the first derivative, we have:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial p} =\n",
    "        \\begin{cases}\n",
    "            -1/p      \\quad\\qquad\\qquad if\\quad y = \\mathrm{DIG\\_B} \\\\\n",
    "            -1/(1-p)  \\quad\\qquad  \\mathrm{otherwise}\n",
    "        \\end{cases}\n",
    "$$        \n",
    "\n",
    "Next, we consider the derivate of signmoid (computation details ommitted).\n",
    "\n",
    "$$\n",
    "\\frac{\\partial p}{\\partial z} = p(1-p)\n",
    "$$\n",
    "\n",
    "Finally, the derivative of $z$ with respect to $w$ is simply $x$ (flattened). Combining everything above, we have:\n",
    "\n",
    "$$\n",
    "    \\frac{\\partial L}{\\partial p}.\\frac{\\partial p}{\\partial z}.\\frac{\\partial z}{\\partial w} =\n",
    "            \\begin{cases}\n",
    "                  (p-1).x  \\quad if\\quad y = \\mathrm{DIG\\_B} \\\\\n",
    "                   p.x     \\quad\\qquad \\mathrm{otherwise}\n",
    "            \\end{cases}\n",
    "$$\n",
    "\n",
    "Therefore, we can define the linear backpropogration function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830aed72",
   "metadata": {
    "id": "830aed72"
   },
   "outputs": [],
   "source": [
    "def linear_backprop(w, x, y):\n",
    "    z = w.dot(x.flatten())\n",
    "    p = sigmoid(z)\n",
    "    dl_dp = -(1 if y == DIG_B else -1) / (p if y == DIG_B else 1-p)\n",
    "    dp_dz = p * (1-p)\n",
    "    dz_dw = x.flatten()\n",
    "\n",
    "    dl_dw = dl_dp * dp_dz * dz_dw\n",
    "    return dl_dw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3ab59b",
   "metadata": {
    "id": "5c3ab59b"
   },
   "source": [
    "Let’s do a sanity check to make sure that the linear predictor is actually learning something. Using just one sample, we should expect the loss to decrease for each epoch. We also define a more generalized version of the function close_enough to compare two arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2383356e",
   "metadata": {
    "id": "2383356e"
   },
   "outputs": [],
   "source": [
    "close_enough = lambda a, b: np.linalg.norm(np.array(b-a).flatten()) < 1e-6\n",
    "\n",
    "for _ in range(10):\n",
    "    w = np.random.randn(SIDE*SIDE) / np.sqrt(SIDE*SIDE)\n",
    "    x = x_train[0]\n",
    "    y = y_train[0]\n",
    "\n",
    "    g = linear_backprop(w, x, y)\n",
    "\n",
    "    before = judge(lambda xx: linear_predict(w, xx), [x], [y])['loss']\n",
    "    w = w - 0.01*g\n",
    "    after = judge(lambda xx: linear_predict(w, xx), [x], [y])['loss']\n",
    "    assert(after < before)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6b32cc",
   "metadata": {
    "id": "9f6b32cc"
   },
   "source": [
    " #### Building the SGD engine\n",
    " Next, we define a function that allows us to retrieve the next training example\n",
    " using a global index variable. We also initialize the random weights, define some\n",
    " learning parameters and number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1284bfa",
   "metadata": {
    "id": "f1284bfa"
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "\n",
    "def next_training_example():\n",
    "    global idx\n",
    "    xy = x_train[idx], y_train[idx]\n",
    "    idx += 1\n",
    "    idx %= N\n",
    "    return xy\n",
    "\n",
    "w = np.random.randn(SIDE*SIDE) / np.sqrt(SIDE*SIDE)\n",
    "LEARNING_RATE = 0.1\n",
    "epochs = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec734f9",
   "metadata": {
    "id": "eec734f9"
   },
   "source": [
    "Now that everything is working, we can finally build our first SGD engine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813ec741",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "813ec741",
    "outputId": "a786f038-1cd7-4a3a-a103-e2c2aa2743b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at step      0tr acc0.50 tr loss 1.188\n",
      "at step   1000tr acc0.95 tr loss 0.137\n",
      "at step   2000tr acc0.95 tr loss 0.160\n",
      "at step   3000tr acc0.95 tr loss 0.143\n",
      "at step   4000tr acc0.95 tr loss 0.174\n",
      "at step   5000tr acc0.95 tr loss 0.151\n",
      "at step   6000tr acc0.97 tr loss 0.116\n",
      "at step   7000tr acc0.95 tr loss 0.209\n",
      "at step   8000tr acc0.94 tr loss 0.195\n",
      "at step   9000tr acc0.92 tr loss 0.289\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    x, y = next_training_example()\n",
    "    g = linear_backprop(w, x, y)\n",
    "    w = w - LEARNING_RATE * g\n",
    "\n",
    "    if t % 1000:\n",
    "        continue\n",
    "\n",
    "    ms = judge(lambda x: linear_predict(w, x), x_train, y_train)\n",
    "    print('at step {:6d}'.format(t) +\n",
    "          'tr acc{:4.2f} tr loss {:5.3f}'.format(ms['acc'], ms['loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d164c8",
   "metadata": {
    "id": "96d164c8"
   },
   "source": [
    "Wetrain the linear predictor with a fixed learning rate for 10,000 epochs. For every 1,000 epoch, we evalute the model to obtain its training accuracy and loss. We get the following output (note that your results may differ due to randomness):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea104b0",
   "metadata": {
    "id": "eea104b0"
   },
   "source": [
    "As shown above, the model achieves a 96% accuracy! However, the model seems to reach its optimal performance in only 1,000 epochs. The loss indicates that the model is unstable, as it fluctuates between 0.11 and 0.17. This may be due to a relatively large learning rate, which prevents the training from stabilizing. Therefore, we can try a learning rate scheduler that decays the learning rate slowly overtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7310625",
   "metadata": {
    "id": "b7310625"
   },
   "outputs": [],
   "source": [
    "LR = LEARNING_RATE * 1000. / (1000. + t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8976d46",
   "metadata": {
    "id": "c8976d46"
   },
   "source": [
    " Additionally, increase the number of epochs, and get the following output (again,\n",
    " your results may differ):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd64fe96",
   "metadata": {
    "id": "cd64fe96"
   },
   "source": [
    "As shown above, we reached a lower loss at 0.087! From our exploration, it’s evident that even a linear model, despite its inherent simplicity, can exhibit profound capabilities in addressing complicated tasks like image classification, achieving a 97% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83f7389",
   "metadata": {
    "id": "f83f7389"
   },
   "source": [
    "### Vanilla Models\n",
    " Let’s move on to vanilla feed-forward neural networks! There are many high level deep learning frameworks (ie. PyTorch and TensorFlow) that cansimplify the following code in just a fewlines, but building the network froms cratch enables us to grasp the fundamentals. We first build the following network architecture:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cf57e5",
   "metadata": {
    "id": "44cf57e5"
   },
   "source": [
    "```\n",
    "x\n",
    "h0-------->z1--->h1-------->z2--->h2-------->z3------>p\n",
    " |\n",
    " |\n",
    " |         |     |\n",
    " |         |     |           |     |\n",
    " | C*      |lrelu|     B*    |lrelu|    A*    |sigmoid|\n",
    " |         |     |           |     |  \n",
    " |         |     |           1\n",
    " |         1\n",
    " |\n",
    " D0        D1    D1          D2    D2         D3      1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a65e59",
   "metadata": {
    "id": "f7a65e59"
   },
   "source": [
    "The inputs $x$ does through the network, layer by layer, to the output. Recall that the feed-forward neural network consists of one input layer, a fixed number of hidden layers, and one output layer. In our example, the networks consists fo two hideen layers, each equipped with leaky ReLU as it's activation function. Leaky ReLU is the modified version of ReLU which address the issue of vanishing gradients\n",
    "\n",
    "$$\n",
    "    \\mathrm{lrelu}(z) = \\mathrm{max}(z/10, z)\n",
    "$$\n",
    "\n",
    "The last row of the diagram indicates the dimensions of layer at each layer. Since our input is a 28x28 image, the input to the network is a flattened array of 784 dimension. For simplicity we set D1 = D2 = 32, which is more so an arbritary choice. In practice, the number of neurons in hidden layers is often chosen to be power of 2, which can result in computational efficiency due to how hardware architectures like GPUs are designed. Notice the \"1\" below each layer? That is the bias term added to each layer. Now, we build this vanilla network and initialize it with random weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447c5cee",
   "metadata": {
    "id": "447c5cee"
   },
   "outputs": [],
   "source": [
    "D0 = SIDE*SIDE\n",
    "D1, D2, D3 = 32, 32, 1\n",
    "\n",
    "def vanilla_init():\n",
    "    A = np.random.randn(    D2) / np.sqrt( 1+D2)\n",
    "    B = np.random.randn(D2, D1) / np.sqrt(D2+D1)\n",
    "    C = np.random.randn(D1, D0) / np.sqrt(D1+D0)\n",
    "\n",
    "    return (A, B, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eb6e2e",
   "metadata": {
    "id": "c3eb6e2e"
   },
   "source": [
    "Theweights are initialized using the Xavier initialization, which scales the weights by the inverse of the square root of the sum of the input and output sizes. This helps to achieve a variance of activations that remain the same across layers, facilitating better convergence during training. Next, we define the activation function and the feed-forward prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10e66a5",
   "metadata": {
    "id": "b10e66a5"
   },
   "outputs": [],
   "source": [
    "lrelu = lambda z: np.maximum(z/10, z)\n",
    "\n",
    "def vanilla_predict(abc, x):\n",
    "    A, B, C = abc\n",
    "\n",
    "    h0 = x.flatten()\n",
    "    z1 = C.dot(h0)\n",
    "    h1 = lrelu(z1)\n",
    "\n",
    "    z2 = B.dot(h1)\n",
    "    h2 = lrelu(z2)\n",
    "\n",
    "    z3 = A.dot(h2)\n",
    "    p = sigmoid(z3)\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7909fdd5",
   "metadata": {
    "id": "7909fdd5"
   },
   "source": [
    "This function passes the input x through the network, layer by layer, with the sigmoid function at the end to ensure that the output is between 0 and 1, indicating the prediction probability. Similarly, we perform a sanity check on a dummy predictor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fd1c32",
   "metadata": {
    "id": "d7fd1c32"
   },
   "outputs": [],
   "source": [
    "A, B, C = vanilla_init()\n",
    "vsa = judge(lambda x: vanilla_predict((+A, B, C), x), x_train, y_train)['acc']\n",
    "vsb = judge(lambda x: vanilla_predict((-A, B, C), x), x_train, y_train)['acc']\n",
    "assert(close_enough(vsa+vsb, 1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc18880",
   "metadata": {
    "id": "1cc18880"
   },
   "source": [
    "Here, vsa computes the accuracy using the initial random weights, whereas vsb computes the accuracy when the sign of the weights of the output layer is flipped, essentially leading to opposite predictions for the same input. Therefore, the accuracy of the two predictors must sum up to one. Next, consider another predictor where A is set to zero. In this case, the output layer’s activation are forced to be near 0.5, turning the model into a fifty-fifty predictor. Recall that the loss for this type of predictor should have loss of log2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cf1192",
   "metadata": {
    "id": "21cf1192"
   },
   "outputs": [],
   "source": [
    "ffl = judge(lambda x: vanilla_predict((0*A, B, C), x), x_train, y_train)['loss']\n",
    "assert(close_enough(ffl, np.log(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ded4b21",
   "metadata": {
    "id": "8ded4b21"
   },
   "source": [
    "To further understand the effects of these weights, we can perform an interesting experiment. Suppose we force all the weights to be positive, then the values in each neuron would be positive, leading to a prediction that always favors DIG_B. We can verify this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07957db3",
   "metadata": {
    "id": "07957db3"
   },
   "outputs": [],
   "source": [
    "x = x_train[0]\n",
    "y = y_train[0]\n",
    "A = np.abs(A)\n",
    "B = np.abs(B)\n",
    "C = np.abs(C)\n",
    "\n",
    "acc_ppp = judge(lambda x: vanilla_predict((A, B, C), x), [x], [DIG_B])['acc']\n",
    "assert(close_enough(acc_ppp, 1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321e792d",
   "metadata": {
    "id": "321e792d"
   },
   "source": [
    "Suppose we flip one of the three matrices, such that all entries in the matrix are negative. Therefore, the inputs and outputs of that particular layer would be opposite, leading to a prediction that always favors DIG_A. We can verify this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6c5196",
   "metadata": {
    "id": "ab6c5196"
   },
   "outputs": [],
   "source": [
    "acc_ppn = judge(lambda x: vanilla_predict((A, B, -C), x), [x], [DIG_B])['acc']\n",
    "acc_pnp = judge(lambda x: vanilla_predict((A, -B, C), x), [x], [DIG_B])['acc']\n",
    "assert close_enough(acc_ppn, 0.)\n",
    "assert close_enough(acc_pnp, 0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d30629",
   "metadata": {
    "id": "c7d30629"
   },
   "source": [
    "Similarly, if we flip two of the matrices, the two negative weights will end up negating each other’s effect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c81fb0",
   "metadata": {
    "id": "59c81fb0"
   },
   "outputs": [],
   "source": [
    "acc_pnn = judge(lambda x: vanilla_predict((A,-B,-C), x), [x], [DIG_B])['acc']\n",
    "assert(close_enough(acc_pnn, 1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a967879",
   "metadata": {
    "id": "8a967879"
   },
   "source": [
    "####  Vanilla Backpropagation\n",
    "Now, we are ready to implement the back-propagation for the vanilla model. Recall that the leaky ReLU is defined as:\n",
    "\n",
    "$$\n",
    "\\mathrm{lrelu}(z) = \\mathrm{max}(z/10, z) = \\begin{cases}\n",
    "    z     \\qquad \\mathrm{if}\\quad z \\gt 0 \\\\\n",
    "    z/10  \\quad \\mathrm{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "We compute it's gradient:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathrm{lrelu}}{\\partial z} = \\begin{cases}\n",
    "    1     \\qquad \\mathrm{if}\\quad z \\gt 0 \\\\\n",
    "    0.1   \\qquad  \\mathrm{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Observe that leaky ReLU is not diferentiable at $z = 0$, although it is typically defined to be the same as the negative side to avoid undefined values. In this example, we define it to be the average of the two derivatives (ie. 0.55). Note that in practice, the gradient at z = 0 does not really matter due to floating-point arithmetic in Python. The probability of getting an exact value of 0 is extremely small. Therefore, we can define the derivative as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eb841c",
   "metadata": {
    "id": "f7eb841c"
   },
   "outputs": [],
   "source": [
    "step = lambda z: np.heaviside(z, 0.5)\n",
    "dlrelu_dz = lambda z: 0.1 + (1. - 0.1)*step(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b07f934",
   "metadata": {
    "id": "5b07f934"
   },
   "source": [
    "Note that:\n",
    "\n",
    "$$\n",
    "\\mathrm{np.heaviside}(z, c) = \\begin{cases}\n",
    "    0 \\qquad \\mathrm{if} z \\lt 0 \\\\\n",
    "    c \\qquad \\mathrm{if} z = 0 \\\\\n",
    "    1 \\qquad \\mathrm{if} z \\gt 0 \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Consider the weights $abc = (A, B, C)$, and give sample $x$ with label $y$. For each update, the function first performs forward pass through the network to compute the probability of class DIG_B of the given network for $x$.\n",
    "\n",
    "Next, the function computes the gradients of the loss with respect to the parameters by applying the chain rule backward through the network, from the output layer to the input layer. This part calculates how much each weight contributed to the error in the output and thus, how much the weights should be adjusted. Here, np.outer computes the gradient for each weight in the layer based on how much changing that specific weight would affect the loss. The resulting matrix of the outer product has the same shape as the weight matrix, and each element of the result represents the partial derivative of the loss with respect to the corresponding weight in the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b118f98",
   "metadata": {
    "id": "8b118f98"
   },
   "outputs": [],
   "source": [
    "def vanilla_backprop(abc, x, y):\n",
    "    A, B, C = abc\n",
    "\n",
    "    h0 = x.flatten()\n",
    "    z1 = C.dot(h0)\n",
    "    h1 = lrelu(z1)\n",
    "\n",
    "    z2 = B.dot(h1)\n",
    "    h2 = lrelu(z2)\n",
    "\n",
    "    z3 = A.dot(h2)\n",
    "    p = sigmoid(z3)\n",
    "\n",
    "    dl_dz3 = p - (1 if y == DIG_B else 0)\n",
    "    dl_dh2 = dl_dz3 * A\n",
    "    dl_dz2 = dl_dh2 * dlrelu_dz(z2)\n",
    "    dl_dh1 = dl_dz2.dot(B)\n",
    "    dl_dz1 = dl_dh1 * dlrelu_dz(z1)\n",
    "\n",
    "    dl_dA = dl_dz3 * h2\n",
    "    dl_dB = np.outer(dl_dz2, h1)\n",
    "    dl_dC = np.outer(dl_dz1, h0)\n",
    "\n",
    "    return dl_dA, dl_dB, dl_dC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d94f85",
   "metadata": {
    "id": "c4d94f85"
   },
   "source": [
    "Next, we define a displacement function that updates the parameters of the network. For each parameter, the corresponding gradient is multiplied by the learning rate then added to the current parameter value, performing a gradient descent update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1e9e05",
   "metadata": {
    "id": "0f1e9e05"
   },
   "outputs": [],
   "source": [
    "def vanilla_displace(abc, coef, g):\n",
    "    A, B, C = abc\n",
    "    gA, gB, gC = g\n",
    "    return (A + coef * gA,\n",
    "            B + coef * gB,\n",
    "            C + coef * gC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdae418",
   "metadata": {
    "id": "0fdae418"
   },
   "source": [
    " Combining everything above, let’s train the vanilla network!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b895fcc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b895fcc",
    "outputId": "14b2f0df-95e1-41d8-b6e3-6dfd370ff67a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at step      0tr acc 0.5489 tr loss 0.689\n",
      "at step   1000tr acc 0.9478 tr loss 0.177\n",
      "at step   2000tr acc 0.9443 tr loss 0.156\n",
      "at step   3000tr acc 0.9679 tr loss 0.097\n",
      "at step   4000tr acc 0.9690 tr loss 0.089\n",
      "at step   5000tr acc 0.9710 tr loss 0.082\n",
      "at step   6000tr acc 0.9758 tr loss 0.067\n",
      "at step   7000tr acc 0.9761 tr loss 0.068\n",
      "at step   8000tr acc 0.9740 tr loss 0.068\n",
      "at step   9000tr acc 0.9785 tr loss 0.065\n",
      "at step  10000tr acc 0.9743 tr loss 0.078\n",
      "at step  11000tr acc 0.9813 tr loss 0.055\n",
      "at step  12000tr acc 0.9832 tr loss 0.048\n",
      "at step  13000tr acc 0.9785 tr loss 0.064\n",
      "at step  14000tr acc 0.9822 tr loss 0.048\n",
      "at step  15000tr acc 0.9816 tr loss 0.054\n",
      "at step  16000tr acc 0.9835 tr loss 0.048\n",
      "at step  17000tr acc 0.9860 tr loss 0.043\n",
      "at step  18000tr acc 0.9868 tr loss 0.037\n",
      "at step  19000tr acc 0.9842 tr loss 0.042\n",
      "at step  20000tr acc 0.9802 tr loss 0.051\n",
      "at step  21000tr acc 0.9854 tr loss 0.042\n",
      "at step  22000tr acc 0.9840 tr loss 0.044\n",
      "at step  23000tr acc 0.9873 tr loss 0.036\n",
      "at step  24000tr acc 0.9880 tr loss 0.036\n",
      "at step  25000tr acc 0.9872 tr loss 0.036\n",
      "at step  26000tr acc 0.9882 tr loss 0.033\n",
      "at step  27000tr acc 0.9865 tr loss 0.041\n",
      "at step  28000tr acc 0.9878 tr loss 0.035\n",
      "at step  29000tr acc 0.9901 tr loss 0.029\n",
      "at step  30000tr acc 0.9860 tr loss 0.039\n",
      "at step  31000tr acc 0.9885 tr loss 0.032\n",
      "at step  32000tr acc 0.9892 tr loss 0.030\n",
      "at step  33000tr acc 0.9902 tr loss 0.027\n",
      "at step  34000tr acc 0.9884 tr loss 0.033\n",
      "at step  35000tr acc 0.9908 tr loss 0.027\n",
      "at step  36000tr acc 0.9908 tr loss 0.029\n",
      "at step  37000tr acc 0.9906 tr loss 0.026\n",
      "at step  38000tr acc 0.9914 tr loss 0.025\n",
      "at step  39000tr acc 0.9907 tr loss 0.026\n",
      "at step  40000tr acc 0.9899 tr loss 0.027\n",
      "at step  41000tr acc 0.9921 tr loss 0.023\n",
      "at step  42000tr acc 0.9886 tr loss 0.032\n",
      "at step  43000tr acc 0.9927 tr loss 0.023\n",
      "at step  44000tr acc 0.9908 tr loss 0.026\n",
      "at step  45000tr acc 0.9914 tr loss 0.026\n",
      "at step  46000tr acc 0.9915 tr loss 0.023\n",
      "at step  47000tr acc 0.9922 tr loss 0.023\n",
      "at step  48000tr acc 0.9925 tr loss 0.021\n",
      "at step  49000tr acc 0.9930 tr loss 0.020\n",
      "at step  50000tr acc 0.9931 tr loss 0.020\n",
      "at step  51000tr acc 0.9908 tr loss 0.026\n",
      "at step  52000tr acc 0.9930 tr loss 0.021\n",
      "at step  53000tr acc 0.9935 tr loss 0.019\n",
      "at step  54000tr acc 0.9937 tr loss 0.019\n",
      "at step  55000tr acc 0.9938 tr loss 0.019\n",
      "at step  56000tr acc 0.9935 tr loss 0.018\n",
      "at step  57000tr acc 0.9925 tr loss 0.022\n",
      "at step  58000tr acc 0.9937 tr loss 0.018\n",
      "at step  59000tr acc 0.9921 tr loss 0.022\n",
      "at step  60000tr acc 0.9942 tr loss 0.019\n",
      "at step  61000tr acc 0.9947 tr loss 0.016\n",
      "at step  62000tr acc 0.9947 tr loss 0.016\n",
      "at step  63000tr acc 0.9929 tr loss 0.020\n",
      "at step  64000tr acc 0.9950 tr loss 0.016\n",
      "at step  65000tr acc 0.9954 tr loss 0.015\n",
      "at step  66000tr acc 0.9953 tr loss 0.015\n",
      "at step  67000tr acc 0.9944 tr loss 0.017\n",
      "at step  68000tr acc 0.9947 tr loss 0.016\n",
      "at step  69000tr acc 0.9941 tr loss 0.017\n",
      "at step  70000tr acc 0.9957 tr loss 0.015\n",
      "at step  71000tr acc 0.9947 tr loss 0.016\n",
      "at step  72000tr acc 0.9937 tr loss 0.018\n",
      "at step  73000tr acc 0.9949 tr loss 0.016\n",
      "at step  74000tr acc 0.9953 tr loss 0.013\n",
      "at step  75000tr acc 0.9955 tr loss 0.014\n",
      "at step  76000tr acc 0.9960 tr loss 0.014\n",
      "at step  77000tr acc 0.9963 tr loss 0.013\n",
      "at step  78000tr acc 0.9959 tr loss 0.014\n",
      "at step  79000tr acc 0.9948 tr loss 0.015\n",
      "at step  80000tr acc 0.9955 tr loss 0.014\n",
      "at step  81000tr acc 0.9955 tr loss 0.014\n",
      "at step  82000tr acc 0.9962 tr loss 0.013\n",
      "at step  83000tr acc 0.9958 tr loss 0.013\n",
      "at step  84000tr acc 0.9963 tr loss 0.012\n",
      "at step  85000tr acc 0.9955 tr loss 0.013\n",
      "at step  86000tr acc 0.9956 tr loss 0.013\n",
      "at step  87000tr acc 0.9960 tr loss 0.013\n",
      "at step  88000tr acc 0.9965 tr loss 0.012\n",
      "at step  89000tr acc 0.9953 tr loss 0.014\n",
      "at step  90000tr acc 0.9967 tr loss 0.012\n",
      "at step  91000tr acc 0.9962 tr loss 0.012\n",
      "at step  92000tr acc 0.9964 tr loss 0.012\n",
      "at step  93000tr acc 0.9964 tr loss 0.012\n",
      "at step  94000tr acc 0.9969 tr loss 0.011\n",
      "at step  95000tr acc 0.9971 tr loss 0.011\n",
      "at step  96000tr acc 0.9966 tr loss 0.011\n",
      "at step  97000tr acc 0.9969 tr loss 0.011\n",
      "at step  98000tr acc 0.9959 tr loss 0.012\n",
      "at step  99000tr acc 0.9963 tr loss 0.011\n",
      "at step 100000tr acc 0.9970 tr loss 0.010\n",
      "at step 101000tr acc 0.9956 tr loss 0.013\n",
      "at step 102000tr acc 0.9967 tr loss 0.011\n",
      "at step 103000tr acc 0.9943 tr loss 0.016\n",
      "at step 104000tr acc 0.9973 tr loss 0.010\n",
      "at step 105000tr acc 0.9973 tr loss 0.010\n",
      "at step 106000tr acc 0.9975 tr loss 0.010\n",
      "at step 107000tr acc 0.9975 tr loss 0.010\n",
      "at step 108000tr acc 0.9971 tr loss 0.010\n",
      "at step 109000tr acc 0.9973 tr loss 0.009\n",
      "at step 110000tr acc 0.9951 tr loss 0.015\n",
      "at step 111000tr acc 0.9975 tr loss 0.009\n",
      "at step 112000tr acc 0.9975 tr loss 0.009\n",
      "at step 113000tr acc 0.9970 tr loss 0.010\n",
      "at step 114000tr acc 0.9971 tr loss 0.010\n",
      "at step 115000tr acc 0.9968 tr loss 0.010\n",
      "at step 116000tr acc 0.9975 tr loss 0.009\n",
      "at step 117000tr acc 0.9976 tr loss 0.009\n",
      "at step 118000tr acc 0.9951 tr loss 0.013\n",
      "at step 119000tr acc 0.9980 tr loss 0.009\n",
      "at step 120000tr acc 0.9975 tr loss 0.009\n",
      "at step 121000tr acc 0.9975 tr loss 0.008\n",
      "at step 122000tr acc 0.9978 tr loss 0.009\n",
      "at step 123000tr acc 0.9977 tr loss 0.008\n",
      "at step 124000tr acc 0.9980 tr loss 0.008\n",
      "at step 125000tr acc 0.9976 tr loss 0.008\n",
      "at step 126000tr acc 0.9980 tr loss 0.008\n",
      "at step 127000tr acc 0.9981 tr loss 0.008\n",
      "at step 128000tr acc 0.9972 tr loss 0.010\n",
      "at step 129000tr acc 0.9983 tr loss 0.008\n",
      "at step 130000tr acc 0.9976 tr loss 0.009\n",
      "at step 131000tr acc 0.9980 tr loss 0.008\n",
      "at step 132000tr acc 0.9981 tr loss 0.008\n",
      "at step 133000tr acc 0.9981 tr loss 0.007\n",
      "at step 134000tr acc 0.9981 tr loss 0.008\n",
      "at step 135000tr acc 0.9982 tr loss 0.007\n",
      "at step 136000tr acc 0.9982 tr loss 0.007\n",
      "at step 137000tr acc 0.9982 tr loss 0.007\n",
      "at step 138000tr acc 0.9984 tr loss 0.007\n",
      "at step 139000tr acc 0.9982 tr loss 0.007\n",
      "at step 140000tr acc 0.9980 tr loss 0.008\n",
      "at step 141000tr acc 0.9984 tr loss 0.007\n",
      "at step 142000tr acc 0.9982 tr loss 0.008\n",
      "at step 143000tr acc 0.9982 tr loss 0.007\n",
      "at step 144000tr acc 0.9983 tr loss 0.007\n",
      "at step 145000tr acc 0.9985 tr loss 0.007\n",
      "at step 146000tr acc 0.9983 tr loss 0.007\n",
      "at step 147000tr acc 0.9986 tr loss 0.007\n",
      "at step 148000tr acc 0.9975 tr loss 0.008\n",
      "at step 149000tr acc 0.9983 tr loss 0.007\n",
      "at step 150000tr acc 0.9984 tr loss 0.007\n",
      "at step 151000tr acc 0.9984 tr loss 0.007\n",
      "at step 152000tr acc 0.9981 tr loss 0.008\n",
      "at step 153000tr acc 0.9985 tr loss 0.007\n",
      "at step 154000tr acc 0.9987 tr loss 0.006\n",
      "at step 155000tr acc 0.9986 tr loss 0.007\n",
      "at step 156000tr acc 0.9985 tr loss 0.006\n",
      "at step 157000tr acc 0.9982 tr loss 0.007\n",
      "at step 158000tr acc 0.9984 tr loss 0.007\n",
      "at step 159000tr acc 0.9986 tr loss 0.006\n",
      "at step 160000tr acc 0.9980 tr loss 0.007\n",
      "at step 161000tr acc 0.9986 tr loss 0.006\n",
      "at step 162000tr acc 0.9979 tr loss 0.008\n",
      "at step 163000tr acc 0.9986 tr loss 0.006\n",
      "at step 164000tr acc 0.9986 tr loss 0.006\n",
      "at step 165000tr acc 0.9987 tr loss 0.006\n",
      "at step 166000tr acc 0.9987 tr loss 0.006\n",
      "at step 167000tr acc 0.9987 tr loss 0.006\n",
      "at step 168000tr acc 0.9987 tr loss 0.006\n",
      "at step 169000tr acc 0.9975 tr loss 0.009\n",
      "at step 170000tr acc 0.9986 tr loss 0.006\n",
      "at step 171000tr acc 0.9988 tr loss 0.006\n",
      "at step 172000tr acc 0.9984 tr loss 0.006\n",
      "at step 173000tr acc 0.9988 tr loss 0.006\n",
      "at step 174000tr acc 0.9985 tr loss 0.006\n",
      "at step 175000tr acc 0.9989 tr loss 0.006\n",
      "at step 176000tr acc 0.9989 tr loss 0.006\n",
      "at step 177000tr acc 0.9984 tr loss 0.007\n",
      "at step 178000tr acc 0.9988 tr loss 0.005\n",
      "at step 179000tr acc 0.9989 tr loss 0.006\n",
      "at step 180000tr acc 0.9987 tr loss 0.006\n",
      "at step 181000tr acc 0.9984 tr loss 0.006\n",
      "at step 182000tr acc 0.9991 tr loss 0.005\n",
      "at step 183000tr acc 0.9991 tr loss 0.005\n",
      "at step 184000tr acc 0.9986 tr loss 0.006\n",
      "at step 185000tr acc 0.9990 tr loss 0.005\n",
      "at step 186000tr acc 0.9989 tr loss 0.006\n",
      "at step 187000tr acc 0.9988 tr loss 0.006\n",
      "at step 188000tr acc 0.9992 tr loss 0.005\n",
      "at step 189000tr acc 0.9987 tr loss 0.006\n",
      "at step 190000tr acc 0.9989 tr loss 0.006\n",
      "at step 191000tr acc 0.9988 tr loss 0.005\n",
      "at step 192000tr acc 0.9990 tr loss 0.005\n",
      "at step 193000tr acc 0.9986 tr loss 0.006\n",
      "at step 194000tr acc 0.9992 tr loss 0.005\n",
      "at step 195000tr acc 0.9993 tr loss 0.005\n",
      "at step 196000tr acc 0.9991 tr loss 0.005\n",
      "at step 197000tr acc 0.9992 tr loss 0.005\n",
      "at step 198000tr acc 0.9990 tr loss 0.005\n",
      "at step 199000tr acc 0.9991 tr loss 0.005\n",
      "at step 200000tr acc 0.9991 tr loss 0.005\n",
      "at step 201000tr acc 0.9988 tr loss 0.006\n",
      "at step 202000tr acc 0.9992 tr loss 0.005\n",
      "at step 203000tr acc 0.9990 tr loss 0.005\n",
      "at step 204000tr acc 0.9992 tr loss 0.005\n",
      "at step 205000tr acc 0.9987 tr loss 0.005\n",
      "at step 206000tr acc 0.9992 tr loss 0.005\n",
      "at step 207000tr acc 0.9984 tr loss 0.006\n",
      "at step 208000tr acc 0.9992 tr loss 0.005\n",
      "at step 209000tr acc 0.9993 tr loss 0.004\n",
      "at step 210000tr acc 0.9992 tr loss 0.005\n",
      "at step 211000tr acc 0.9988 tr loss 0.006\n",
      "at step 212000tr acc 0.9992 tr loss 0.004\n",
      "at step 213000tr acc 0.9992 tr loss 0.004\n",
      "at step 214000tr acc 0.9993 tr loss 0.005\n",
      "at step 215000tr acc 0.9992 tr loss 0.005\n",
      "at step 216000tr acc 0.9990 tr loss 0.005\n",
      "at step 217000tr acc 0.9992 tr loss 0.004\n",
      "at step 218000tr acc 0.9994 tr loss 0.004\n",
      "at step 219000tr acc 0.9992 tr loss 0.005\n",
      "at step 220000tr acc 0.9993 tr loss 0.004\n",
      "at step 221000tr acc 0.9989 tr loss 0.005\n",
      "at step 222000tr acc 0.9993 tr loss 0.004\n",
      "at step 223000tr acc 0.9993 tr loss 0.005\n",
      "at step 224000tr acc 0.9992 tr loss 0.005\n",
      "at step 225000tr acc 0.9992 tr loss 0.004\n"
     ]
    }
   ],
   "source": [
    "abc = vanilla_init()\n",
    "T = 15001\n",
    "\n",
    "# parameters for momentum\n",
    "m = vanilla_displace(abc, -1., abc)\n",
    "BETA = 0.9\n",
    "\n",
    "for t in range(T*15+1):\n",
    "    x, y = next_training_example()\n",
    "    g = vanilla_backprop(abc, x, y)\n",
    "    LR = LEARNING_RATE * 4000. / (4000 + t)\n",
    "\n",
    "    '''\n",
    "    Uncomment this line and comment lines 18-20 for eliminating momentum\n",
    "    abc = vanilla_displace(abc, -LR, g)\n",
    "    '''\n",
    "\n",
    "    m = vanilla_displace(m, BETA-1, m)\n",
    "    m = vanilla_displace(m, 1, g)\n",
    "    abc = vanilla_displace(abc, -LR, m)\n",
    "\n",
    "    if t % 1000:\n",
    "        continue\n",
    "\n",
    "    ms = judge(lambda x: vanilla_predict(abc, x), x_train, y_train)\n",
    "    print('at step {:6d}'.format(t) +\n",
    "          'tr acc {:4.4f} tr loss {:5.3f}'.format(ms['acc'], ms['loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0bd4ac",
   "metadata": {
    "id": "ab0bd4ac"
   },
   "source": [
    " This indicates that the network reaches a training loss of around 0.05, with an 98 −99% accuracy! Additionally, we can implement the idea of momentum, which also considers gradients from previous updates. We first initialize the momentum to zero after we initialize the weights of the model (at line 2): `m = vanilla_displace(abc,-1., abc)`. This is a hacky way to initialize momentum with the same shape as model parameters. Next, we change the model updates to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c14467",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "72c14467",
    "outputId": "04d044d0-6f65-4cd1-df12-87194b3009a6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nbeta = 0.9\\n\\nm = vanilla_displace(m, beta-1, m)\\nm = vanilla_displace(m, 1, g)\\nabc = vanilla_displace(abc, -LR, m)\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "beta = 0.9\n",
    "\n",
    "m = vanilla_displace(m, beta-1, m)\n",
    "m = vanilla_displace(m, 1, g)\n",
    "abc = vanilla_displace(abc, -LR, m)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f41e4ba",
   "metadata": {
    "id": "3f41e4ba"
   },
   "source": [
    "The parameter beta is the momentum coefficient, which controls how much of the previous gradients to be considered. For example, when β = 0.9, it means 90% of the previous velocity is combined with 10% of the current gradient to update the parameters. Line 2 indicates that we are “forgetting” 10% of the previous velocity (thus 90% remaining), then we the current gradient to the velocity. Then we update the parameters based on the velocity. In practice, we typically\n",
    " set the momentum parameter to some value between 0.8 and 0.99. Using this technique, we can sometimes result in faster convergence and higher accuracy (although the effects are not as profound in this example)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec24ce55",
   "metadata": {
    "id": "ec24ce55"
   },
   "source": [
    " ### Building a CNN\n",
    " For the last model, we will be building a convolutional neural network (CNN). A CNN is a specialized type of neural network designed for processing grid structured input data such as images, where spatial hierarchies and local patterns are crucial. Unlike fully-connected neural networks where each neuron in one layer is connected to every neuron in the next layer, CNNs use convolutional layers to preserve the spatial relationship between pixels by learning image features using small squares of input data. We define the architecture as below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f125dddb",
   "metadata": {
    "id": "f125dddb"
   },
   "source": [
    "```                     \n",
    "                        height x width x channels\n",
    "    \n",
    "x                          28 x 28 x 1\n",
    "           avgpool                                           2 x 2\n",
    "h0                         14 x 14 x 1\n",
    "           conv                                 weight C     5 x 5 x 8 x 1   stride 2 x 2\n",
    "z1                           5 x 5 x 8      \n",
    "           lrelu           \n",
    "h1                           5 x 5 x 8\n",
    "           conv                                 weight B     1 x 1 x 4 x 8   stride 1 x 1\n",
    "z2                           5 x 5 x 4\n",
    "           lrelu\n",
    "h2                           5 x 5 x 4\n",
    "           dense                                weight A     1 x (5 x 5 x 4)\n",
    "z3                                   1\n",
    "           sigmoid\n",
    "p                                    1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4991a7",
   "metadata": {
    "id": "0b4991a7"
   },
   "source": [
    "Let's break down the architecture layer, from top to bottom:\n",
    "1. input x: the input is an image with dimensions 28 x 28 with 1 channel, since it is a grayscale image\n",
    "2. avgpool: this layer performans average pooling with 2 x 2 windows, effectively reducing the spatial dimensions by a factor of 2. After poolng, the dimension becomes 14 x 14 x 1\n",
    "3. conv: the first convolution layer has filters of size 5 x 5, 8 output channels with a 2 x 2 stride. Given the input size of 14 x 14, the feature map size becomes\n",
    "$$\n",
    "\\frac{14 - 5}{2} + 1 = 5\n",
    "$$\n",
    "The output has dimension 5 x 5 x 8. Leaky ReLU does not change the dimensions.\n",
    "4. The second convolution layer has filters of size 1 x 1, 4 output channels and operating on 8 input channels with a stride of 1 x 1. The spatial diemsnions remain the same, but the number of channels changes to 4. The output has dimension 5 x 5 x 4. Leaky ReLU does not change the dimensions.\n",
    "5. We use a fully-connected layer that reduces the dimensions to a singlevalue, followed by a sigmoid activation function which squashes the outpu tbetween 0 and 1, which is what we need for binary classification tasks.\n",
    "\n",
    "Now, we define the functions for average pooling and convolution layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31b7b5c",
   "metadata": {
    "id": "d31b7b5c"
   },
   "outputs": [],
   "source": [
    "def avgpool2x2(x):\n",
    "    H, W, C = x.shape\n",
    "    return ( x[0:H:2, 0:W:2]\n",
    "            +x[0:H:2, 1:W:2]\n",
    "            +x[1:H:2, 0:W:2]\n",
    "            +x[1:H:2, 1:W:2])/4\n",
    "\n",
    "def conv(x, weights, stride=1):\n",
    "    H, W, C = x.shape\n",
    "    KH, KW, OD, ID = weights.shape\n",
    "\n",
    "    assert(C == ID)\n",
    "\n",
    "    HH, WW = int((H - KH + 1)/stride), int((W - KW + 1)/stride)\n",
    "\n",
    "    return np.array(\n",
    "        [[\n",
    "            np.tensordot(\n",
    "                weights,\n",
    "                x[h:h+KH, w:w+KW],\n",
    "                ((0, 1, 3), (0, 1, 2))\n",
    "            )\n",
    "            for w in range(0, WW*stride, stride)]\n",
    "        for h in range(0, HH*stride, stride)]\n",
    "    )\n",
    "\n",
    "def conv_displace(abc, coef, g):\n",
    "  A, B, C = abc\n",
    "  gA, gB, gC = g\n",
    "  return (A + coef * gA,\n",
    "          B + coef * gB,\n",
    "          C + coef * gC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f96c1a",
   "metadata": {
    "id": "96f96c1a"
   },
   "source": [
    "The function `avgpool2x2` performs 2x2 pooling, which means it averages the values of 2x2 adjacent pixels and produces a pooled output, hence reducing the spatial dimensions by a factor of 2. The function `conv` performs convolution operation between the input x and weights with a specified stride. The assertion test ensures that the number of channels in the input is the same as the number of channels to the input depth of the weights ID. The returned value includes the dot products between the weights and the respective regions of the input tensor, considering the stride. It iterates over the height and width of the possible positions of the filter on the input tensor and calculates the corresponding output for each position, eventually creating an array representing the output feature map. Now, we perform some sanity checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc90858",
   "metadata": {
    "id": "6fc90858"
   },
   "outputs": [],
   "source": [
    "aa = np.ones((8, 12, 7))\n",
    "pp = np.ones((4, 6, 7))\n",
    "assert close_enough(avgpool2x2(aa), pp)\n",
    "ww = np.ones((3, 3, 5, 7))\n",
    "cc = (3*3*7)*np.ones((6, 10, 5))\n",
    "assert close_enough(conv(aa, ww, stride=1), cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd09dbc",
   "metadata": {
    "id": "fbd09dbc"
   },
   "source": [
    "We first initialize `aa` as an array of all ones with shape 8 x 12 x 7 (height `x`width `x` channel). When we perform a 2x2 average pooling on it, we effectively shrink the dimensions by a factor of 2. Since all values are ones, the average value in each pooling region is also one. Next, `ww` represents the weights of the convolutional layer and has dimensions 3 x 3 x 5 x 7 (kernel height `x` kernel width `x` output channels `x` input channels). We perform a convolution operation on `aa` with weights `ww` and stride of 1. The output dimensions can be calculated as (8−3+1,12−3+1) = (6,10), thus matching the dimensions of\n",
    " `cc`. Since the weights `ww` are all ones, each value in the output `cc` should be the sum of 3 x 3 x 7 ones from the input `aa`, hence each value in `cc` should be 3·3·7 = 63. These two sanity checks test the scaling and shapes of the functions above. Now, we test if the results match in terms of their orientations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f473f9",
   "metadata": {
    "id": "71f473f9"
   },
   "outputs": [],
   "source": [
    "bb = np.array([1 * np.eye(4), 3 * np.eye(4)])\n",
    "pp = np.array([[[1, 1, 0, 0], [0, 0, 1, 1]]])\n",
    "assert close_enough(avgpool2x2(bb), pp)\n",
    "ww = np.zeros([2, 2, 1, 4])\n",
    "ww[0, 0, :, :] = 1 + np.arange(4)\n",
    "cc = np.array([1, 2, 3])[np.newaxis, :, np.newaxis]\n",
    "assert close_enough(conv(bb, ww, stride=1), cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6621fc8f",
   "metadata": {
    "id": "6621fc8f"
   },
   "source": [
    "`bb` is equivalent to two 4 x 4 identity matrices stacked together, with the second scaled by 3. When avgpool2x2 is applied to `bb`, it performs average pooling over 2 x 2non-overlapping windows. Each channel is an input of dimension 2 x 4, in which the i’th column of the i’th channel being 1 and 3, e.g.\n",
    "\n",
    "$$\n",
    "C1 = {\\left\\lbrack \\matrix{1 & 0 & 0 & 0 \\cr 3 & 0 & 0 & 0} \\right \\rbrack}\n",
    "$$\n",
    "\n",
    " After average pooling with 2 x 2 windows, we have:\n",
    "\n",
    " $$\n",
    " C1 = C2 = {\\left\\lbrack \\matrix{1 & 0}\\right \\rbrack}, C3 = C4 = {\\left\\lbrack \\matrix{0 & 1}\\right \\rbrack}\n",
    " $$\n",
    "\n",
    "Stacking the channels together, we yield an array with dimensions 1 x 2 x 4:\n",
    "\n",
    "$$\n",
    "pp = {\\left\\lbrack \\matrix{1 & 1 & 0 & 0 \\cr 0 & 0 & 1 & 1} \\right \\rbrack}\n",
    "$$\n",
    "\n",
    "For the second sanity check, `w` represents the weights of the convolution layer with dimension 2 x 2 x 1 x 4(kernel height x kernel width x output channels x input channels). Observe that only the top-left values of the weights are non-zero. Therefore, the convolution for each channel would be the sum of the diagonal of `bb` scaled by the corresponding weight in `ww[0, 0]`, which results in the array `cc`.\n",
    "\n",
    "Now, we compute the gradients of the convolution layer. We write two helper functions that, when given the outputs to the convolution layer, give us the gradients with respect to the weights or the inputs to the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700e8837",
   "metadata": {
    "id": "700e8837"
   },
   "outputs": [],
   "source": [
    "def Dw_conv(x, weights_shape, dl_dconv, stride=1):\n",
    "    H, W, C = x.shape\n",
    "    KH, KW, OD, ID = weights_shape\n",
    "    assert C == ID\n",
    "    HH, WW = int((H-KH+1)/stride), int((W-KW+1)/stride)\n",
    "    assert dl_dconv.shape == (HH, WW, OD)\n",
    "\n",
    "    HS, WS = HH*stride, WW*stride\n",
    "    dl_dw = np.array(\n",
    "        [[\n",
    "            np.tensordot(\n",
    "                dl_dconv,\n",
    "                x[dh:dh+HS:stride, dw:dw+WS:stride],\n",
    "                ((0, 1), (0, 1))\n",
    "            )\n",
    "            for dw in range(KW)]\n",
    "        for dh in range(KH)]\n",
    "    )\n",
    "    return dl_dw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e147050",
   "metadata": {
    "id": "1e147050"
   },
   "source": [
    " This function gives us the derivative of the loss with respect to the weights of the\n",
    " convolution layer. Each entry of the derivative:\n",
    "\n",
    " $$\n",
    " \\frac{\\partial L}{\\partial W_{ij}} = \\mathrm{np.tensordot}(\\frac{\\partial L}{\\partial C_{ij}}, x_{sliced}, ((0, 1), (0, 1)))\n",
    " $$\n",
    "\n",
    " computes the sum of element-wise products of the gradients `dl_dconv` and the\n",
    " corresponding input values `x_sliced`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38b381b",
   "metadata": {
    "id": "e38b381b"
   },
   "outputs": [],
   "source": [
    "def Dx_conv(x_shape, weights, dl_dconv, stride):\n",
    "    H, W, C = x_shape\n",
    "    KH, KW, OD, ID = weights.shape\n",
    "    assert C == ID\n",
    "    HH, WW = int((H-KH+1)/stride), int((W-KW+1)/stride)\n",
    "    assert dl_dconv.shape == (HH, WW, OD)\n",
    "\n",
    "    dl_dx = np.zeros((H, W, ID), dtype=np.float32)\n",
    "    for h in range(KH):\n",
    "        for w in range(KW):\n",
    "            dl_dx[h:h+HH*stride:stride, w:w+WW*stride:stride] += (\n",
    "                np.tensordot(\n",
    "                    dl_dconv,\n",
    "                    weights[h, w],\n",
    "                    ((2, ), (0, ))\n",
    "                )\n",
    "            )\n",
    "    return dl_dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9677c4",
   "metadata": {
    "id": "ba9677c4"
   },
   "source": [
    " The second function gives us the derivative of the loss with respect to the inputs\n",
    " to the convolution layer. Each entry:\n",
    "\n",
    " $$\n",
    " \\frac{\\partial L}{\\partial x_{ij}} = \\sum_{h, w} \\frac{\\partial L}{\\partial C_{i-h, j-w}}.W_{hw}\n",
    " $$\n",
    "\n",
    " is the sum over all positions in the kernel, and accumulates the contribution to the gradient at each input location `(i,j)` due to each weight in the kernel. With these building blocks, let’s build the full back-propagation for the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f436afbb",
   "metadata": {
    "id": "f436afbb"
   },
   "outputs": [],
   "source": [
    "def conv_backprop(abc, x, y):\n",
    "    A, B, C = abc\n",
    "\n",
    "    h0 = avgpool2x2(x[:, :, np.newaxis])\n",
    "\n",
    "    z1 = conv(h0, C, stride=2)\n",
    "    h1 = lrelu(z1)\n",
    "\n",
    "    z2 = conv(h1, B, stride=1)\n",
    "    h2 = lrelu(z2)\n",
    "\n",
    "    z3 = A.dot(h2.flatten())\n",
    "    p = sigmoid(z3)\n",
    "\n",
    "    dl_dz3 = p - (1 if y == DIG_B else 0)\n",
    "    dl_dh2 = dl_dz3 * A.reshape(h2.shape)\n",
    "    dl_dz2 = dl_dh2 * dlrelu_dz(z2)\n",
    "    dl_dh1 = Dx_conv(h1.shape, B, dl_dz2, stride=1)\n",
    "    dl_dz1 = dl_dh1 * dlrelu_dz(z1)\n",
    "\n",
    "    dl_dA = dl_dz3 * h2.flatten()\n",
    "    dl_dB = Dw_conv(h1, B.shape, dl_dz2, stride=1)\n",
    "    dl_dC = Dw_conv(h0, C.shape, dl_dz1, stride=2)\n",
    "\n",
    "    return (dl_dA, dl_dB, dl_dC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ms8QBL5ka1bT",
   "metadata": {
    "id": "ms8QBL5ka1bT"
   },
   "source": [
    "Next, we define the prediction function and the displacement function. We omit the implementations here because the prediction function simply returns the pfrom above (line 13), and the displacement function is identical to the one implemented in the vanilla models. We also initialize the random weights (similarly,using normalized Gaussian distributions):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O26sqw1iaLDE",
   "metadata": {
    "id": "O26sqw1iaLDE"
   },
   "outputs": [],
   "source": [
    "def conv_init():\n",
    "  A = np.random.randn(5 * 5 * 4) / np.sqrt(1+5*5*4)\n",
    "  B = np.random.randn(1, 1, 4, 8) / np.sqrt(4+1*1*8)\n",
    "  C = np.random.randn(5, 5, 8, 1) / np.sqrt(8+5*5*1)\n",
    "  return (A, B, C)\n",
    "\n",
    "def conv_predict(abc, x):\n",
    "    A, B, C = abc\n",
    "\n",
    "    h0 = avgpool2x2(x[:, :, np.newaxis])\n",
    "\n",
    "    z1 = conv(h0, C, stride=2)\n",
    "    h1 = lrelu(z1)\n",
    "\n",
    "    z2 = conv(h1, B, stride=1)\n",
    "    h2 = lrelu(z2)\n",
    "\n",
    "    z3 = A.dot(h2.flatten())\n",
    "    p = sigmoid(z3)\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dSM5q5gsbz8E",
   "metadata": {
    "id": "dSM5q5gsbz8E"
   },
   "source": [
    "Finally, let’s train the convolutional neural network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FxCbFTfTbrzh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FxCbFTfTbrzh",
    "outputId": "3dba379d-410c-405a-c4d1-a02bf02ddbeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at step      0tr acc 0.52 tr loss 0.693\n",
      "at step   1000tr acc 0.95 tr loss 0.182\n",
      "at step   2000tr acc 0.96 tr loss 0.122\n",
      "at step   3000tr acc 0.96 tr loss 0.104\n",
      "at step   4000tr acc 0.98 tr loss 0.067\n",
      "at step   5000tr acc 0.98 tr loss 0.062\n",
      "at step   6000tr acc 0.98 tr loss 0.061\n",
      "at step   7000tr acc 0.98 tr loss 0.067\n",
      "at step   8000tr acc 0.98 tr loss 0.053\n",
      "at step   9000tr acc 0.98 tr loss 0.060\n",
      "at step  10000tr acc 0.98 tr loss 0.051\n"
     ]
    }
   ],
   "source": [
    "abc = conv_init()\n",
    "m = conv_displace(abc, -1., abc)\n",
    "\n",
    "for t in range(10001):\n",
    "  x, y = next_training_example()\n",
    "  g = conv_backprop(abc, x, y)\n",
    "  LR = LEARNING_RATE * 4000. / (4000. + t)\n",
    "\n",
    "  abc = conv_displace(abc, -LR, g)\n",
    "\n",
    "  if t % 1000:\n",
    "    continue\n",
    "\n",
    "  ms = judge(lambda x: conv_predict(abc, x), x_train, y_train)\n",
    "  print('at step {:6d}'.format(t) +\n",
    "        'tr acc {:4.2} tr loss {:5.3f}'.format(ms['acc'], ms['loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T0ev7dXUfORU",
   "metadata": {
    "id": "T0ev7dXUfORU"
   },
   "source": [
    "Comparing to previous models, we are able to reach an accuracy of 99% slightly faster!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1yghpKCTfxQl",
   "metadata": {
    "id": "1yghpKCTfxQl"
   },
   "source": [
    "### Evaluation on test set\n",
    "In the final section, we will assess the performance of our three models usingthe testing dataset. The objective is to validate that our models are not merely overfitting to the training dataset but are also capable of generalizing effectively to unseen data. To this end, we load both the training and the testing datasets.Mirroring our previous preprocessing approach, we retain only the two digits of interest, shuffle the samples, and normalize the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n3w8KIaSgcaT",
   "metadata": {
    "id": "n3w8KIaSgcaT"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "def preprocess(x, y):\n",
    "  indices = np.logical_or((y == DIG_A), (y == DIG_B))\n",
    "  x = x[indices]\n",
    "  y = y[indices]\n",
    "  x = x/MAX_PIX_VAL\n",
    "\n",
    "  indices = np.arange(len(x))\n",
    "  np.random.shuffle(indices)\n",
    "\n",
    "  x = x[indices]\n",
    "  y = y[indices]\n",
    "\n",
    "  return x, y\n",
    "\n",
    "np.random.seed(42)\n",
    "x_train, y_train = preprocess(x_train, y_train)\n",
    "x_test, y_test = preprocess(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "glLdXNSPhWYp",
   "metadata": {
    "id": "glLdXNSPhWYp"
   },
   "source": [
    "Next, we will evaluate each model’s performance on the test set. A consistent set of parameters are used across all experiments, in which we use gradient descent with momentum to minimize loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4mBGsOF_h3Pb",
   "metadata": {
    "id": "4mBGsOF_h3Pb"
   },
   "outputs": [],
   "source": [
    "T = 15001\n",
    "LEARNING_RATE = 0.01\n",
    "ANNEAL_T = 4000.\n",
    "BETA = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3Jgyzr3ph_FD",
   "metadata": {
    "id": "3Jgyzr3ph_FD"
   },
   "source": [
    "We also use the following interface for each model to call the corresponding functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WN8UJBxGiC05",
   "metadata": {
    "id": "WN8UJBxGiC05"
   },
   "outputs": [],
   "source": [
    "functions = {\n",
    "    #'linear': [linear_init, linear_backprop, linear_displace, linear_predict],\n",
    "    'vanilla': [vanilla_init, vanilla_backprop, vanilla_displace, vanilla_predict],\n",
    "    'conv': [conv_init, conv_backprop, conv_displace, conv_predict]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5oQNL0IEiabM",
   "metadata": {
    "id": "5oQNL0IEiabM"
   },
   "source": [
    "We compare the models as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZJNAnMgmii6V",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZJNAnMgmii6V",
    "outputId": "484984e7-b091-4ec8-806f-1a2999e51684"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at step      0tr acc 0.522 loss 0.684 te acc 0.506 loss 0.683\n",
      "at step   1000tr acc 0.941 loss 0.184 te acc 0.936 loss 0.183\n",
      "at step   2000tr acc 0.946 loss 0.147 te acc 0.946 loss 0.154\n",
      "at step   3000tr acc 0.964 loss 0.110 te acc 0.955 loss 0.124\n",
      "at step   4000tr acc 0.971 loss 0.087 te acc 0.964 loss 0.099\n",
      "at step   5000tr acc 0.973 loss 0.076 te acc 0.971 loss 0.079\n",
      "at step   6000tr acc 0.974 loss 0.075 te acc 0.973 loss 0.075\n",
      "at step   7000tr acc 0.973 loss 0.080 te acc 0.970 loss 0.085\n",
      "at step   8000tr acc 0.982 loss 0.056 te acc 0.979 loss 0.063\n",
      "at step   9000tr acc 0.982 loss 0.053 te acc 0.978 loss 0.059\n",
      "at step  10000tr acc 0.983 loss 0.053 te acc 0.979 loss 0.064\n",
      "at step  11000tr acc 0.982 loss 0.054 te acc 0.977 loss 0.063\n",
      "at step  12000tr acc 0.985 loss 0.044 te acc 0.979 loss 0.057\n",
      "at step  13000tr acc 0.983 loss 0.052 te acc 0.975 loss 0.064\n",
      "at step  14000tr acc 0.985 loss 0.044 te acc 0.978 loss 0.061\n",
      "at step  15000tr acc 0.986 loss 0.042 te acc 0.982 loss 0.056\n",
      "at step      0tr acc 0.479 loss 0.696 te acc 0.468 loss 0.696\n",
      "at step   1000tr acc 0.944 loss 0.171 te acc 0.940 loss 0.176\n",
      "at step   2000tr acc 0.962 loss 0.111 te acc 0.955 loss 0.111\n",
      "at step   3000tr acc 0.964 loss 0.106 te acc 0.966 loss 0.100\n",
      "at step   4000tr acc 0.972 loss 0.081 te acc 0.970 loss 0.080\n",
      "at step   5000tr acc 0.972 loss 0.082 te acc 0.972 loss 0.080\n",
      "at step   6000tr acc 0.976 loss 0.071 te acc 0.976 loss 0.065\n",
      "at step   7000tr acc 0.977 loss 0.070 te acc 0.978 loss 0.063\n",
      "at step   8000tr acc 0.980 loss 0.057 te acc 0.982 loss 0.052\n",
      "at step   9000tr acc 0.980 loss 0.059 te acc 0.980 loss 0.054\n",
      "at step  10000tr acc 0.982 loss 0.054 te acc 0.981 loss 0.052\n",
      "at step  11000tr acc 0.983 loss 0.056 te acc 0.983 loss 0.051\n",
      "at step  12000tr acc 0.986 loss 0.045 te acc 0.986 loss 0.042\n",
      "at step  13000tr acc 0.978 loss 0.063 te acc 0.979 loss 0.062\n",
      "at step  14000tr acc 0.986 loss 0.043 te acc 0.987 loss 0.038\n",
      "at step  15000tr acc 0.986 loss 0.043 te acc 0.988 loss 0.037\n"
     ]
    }
   ],
   "source": [
    "for model in functions.keys():\n",
    "  init, backprop, displace, predict = functions[model]\n",
    "\n",
    "  w = init()\n",
    "  m = displace(w, -1, w)\n",
    "\n",
    "  for t in range(T):\n",
    "    x, y = next_training_example()\n",
    "    g = backprop(w, x, y)\n",
    "    LR = LEARNING_RATE * ANNEAL_T / (ANNEAL_T + t)\n",
    "\n",
    "    m = displace(m, BETA - 1, m)\n",
    "    m = displace(m, 1, g)\n",
    "    w = displace(w, -LR, m)\n",
    "\n",
    "    if t % 1000:\n",
    "      continue\n",
    "\n",
    "    train = judge(lambda x: predict(w, x), x_train, y_train)\n",
    "    test = judge(lambda x: predict(w, x), x_test, y_test)\n",
    "\n",
    "    print('at step {:6d}'.format(t) +\n",
    "          'tr acc {:4.3f} loss {:5.3f} '.format(train['acc'], train['loss']) +\n",
    "          'te acc {:4.3f} loss {:5.3f}'.format(test['acc'], test['loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CWm28weXjqXv",
   "metadata": {
    "id": "CWm28weXjqXv"
   },
   "source": [
    "We obtain the following loss and accuracies at the end of the training:\n",
    "\n",
    "| Model  | Training Acc | Training loss| Testing Acc  | Testing Loss |\n",
    "|:------:|:------------:|:------------:|:------------:|:------------:|\n",
    "| Linear | 0.970        | 0.092        | 0.969        |       0.095  |\n",
    "| Vanilla| 0.978        | 0.060        | 0.976        |       0.069  |\n",
    "| CNN    | 0.987        | 0.039        | 0.988        |       0.035  |\n",
    "\n",
    "\n",
    "\n",
    "As shown above, the CNN model yields the best performance, both on the training and the testing dataset. In practice, we focus more on the testing accuracy and loss as they represent the performance on unseen observations.\n",
    "Now, let’s perform a “stress” test, in which we test the performance of each\n",
    "model under extreme circumstances. Here, we provide only 1, 000 training samples with added Gaussian noise:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2TrI1Mvl9BJ",
   "metadata": {
    "id": "f2TrI1Mvl9BJ"
   },
   "outputs": [],
   "source": [
    "x = x[:1000]\n",
    "x = x + np.random.randn(*x.shape)\n",
    "x = np.clip(x, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4D_oPc0_qf_9",
   "metadata": {
    "id": "4D_oPc0_qf_9"
   },
   "source": [
    "We obtain the following loss and accuracies at the end of the training:\n",
    "\n",
    "| Model  | Training Acc | Training loss| Testing Acc  | Testing Loss |\n",
    "|:------:|:------------:|:------------:|:------------:|:------------:|\n",
    "| Linear | 1.000        | 0.012        | 0.895        |       0.655  |\n",
    "| Vanilla| 0.926        | 0.286        | 0.893        |       0.647  |\n",
    "| CNN    | 0.821        | 0.394        | 0.914        |       0.225  |\n",
    "\n",
    "Here, we observe some interesting results. The linear model is able to predict all samples in the training dataset correctly, achieving an 100% accuracy rate. The training accuracy decreases as the complexity of the model increases. However, the linear model performs worse on the testing dataset, with the CNN achieving about 2% higher accuracy rate. The linear model and the vanilla model has similar performance on the testing dataset. Note that you may get different\n",
    "results as you run this comparison multiple times, but if given enough time to\n",
    "fully converge (without overfitting), the statements above generally hold true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paiv0m5Hr2I-",
   "metadata": {
    "id": "paiv0m5Hr2I-"
   },
   "source": [
    "### Conclusion\n",
    "If you’re reading this, that means...congratulations! You have just taught a ma\u0002chine to classify hand-written digits! Not only that, the models are able to achieve near- or super-human performance, as human accuracy is reported to be around 97-98% accuracy. In this exercise, we built linear models, vanilla feed-forward networks, and convolution neural networks completely from scratch without relying on external libraries. This enables us to understand some important concepts and the math behind neural networks, such as forward and backward propagation, gradient descent and weight updates.\n",
    "\n",
    "You may be surprised by the impressive performance of a simple linear model\n",
    "paired with a single leaky ReLU. This highlights the power of non-linearity,\n",
    "which can reveal underlying complicated structures. Some state-of-the-art deep\n",
    "neural networks have shown over 99.7% accuracy on classifying all 10 digits. It\n",
    "is worth noting that while machine learning models can achieve higher accuracy\n",
    "than humans on this specific task, it doesn’t necessarily mean they “understand”\n",
    "the data in the same way humans do, as they can be easily fooled with adver\u0002sarial examples. While MNIST is remains highly popular, researchers typically use more complex datasets, such as ImageNet or CIFAR-10, for standard bench\u0002marking.\n",
    "\n",
    "We hope you enjoyed this demo and found it helpful. While our focus here is on\n",
    "binary classification, keep in mind that the MNIST dataset includes samples for\n",
    "ten distinct digits, offering many opportunities for extension. We encourage you\n",
    "to experiment with different model architectures, hyperparameters, and even\n",
    "delve into multi-class classification to further enhance the model’s performance.\n",
    "\n",
    "Happy modeling!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
